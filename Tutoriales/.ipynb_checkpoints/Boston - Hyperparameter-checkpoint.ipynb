{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de precios de las viviendas de Boston\n",
    "\n",
    "## XGBoost en SageMaker (Batch Transform - Hyperparameter Tuning)\n",
    "\n",
    "Como introducción al uso de la API Python de alto nivel de SageMaker, veremos un problema relativamente simple. A saber, usaremos el conjunto de datos de vivienda de Boston para predecir el valor medio de una casa en el área de Boston Mass.\n",
    "\n",
    "## Bosquejo general\n",
    "Por lo general, cuando use una instancia de notebook con SageMaker, procederá con los siguientes pasos. Por supuesto, no todos los pasos deberán realizarse con cada proyecto. Además, hay mucho margen de variación en muchos de los pasos, como verá a lo largo de estas lecciones.\n",
    "\n",
    "1) Descargue o recupere los datos.\n",
    "2) Procesar / preparar los datos.\n",
    "3) Suba los datos procesados a S3.\n",
    "4) Entrenar a un modelo elegido.\n",
    "5) Pruebe el modelo entrenado (generalmente usando un trabajo de transformación por lotes).\n",
    "6) Implemente el modelo entrenado.\n",
    "7) Use el modelo desplegado.\n",
    "En este cuaderno solo cubriremos los pasos 1 a 5, ya que solo queremos tener una idea del uso de SageMaker. En portátiles posteriores, hablaremos sobre la implementación de un modelo entrenado con mucho más detalle.\n",
    "\n",
    "## Paso 0: configuración del portátil\n",
    "Comenzamos configurando todos los bits necesarios necesarios para ejecutar nuestro portátil. Para comenzar eso significa cargar todos los módulos de Python que necesitaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de los módulos anteriores, necesitamos importar los diversos bits de SageMaker que utilizaremos.\n",
    "\n",
    "* sagemaker.session(): Este es un objeto que representa la sesión de SageMaker en la que estamos operando actualmente. Este objeto contiene información útil a la que tendremos que acceder más adelante, como nuestra región.\n",
    "\n",
    "* get_execution_role(): Este es un objeto que representa el rol de IAM que estamos asignados actualmente. Cuando construyamos y lancemos el trabajo de capacitación más adelante, tendremos que decirle qué rol de IAM debería tener. Dado que nuestro caso de uso es relativamente simple, simplemente asignaremos al trabajo de capacitación el rol que tenemos actualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: descargando los datos\n",
    "Afortunadamente, este conjunto de datos se puede recuperar con sklearn, por lo que este paso es relativamente sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: preparar y dividir los datos\n",
    "Dado que se trata de datos tabulares limpios, no necesitamos realizar ningún procesamiento. Sin embargo, necesitamos dividir las filas del conjunto de datos en conjuntos de entrenamiento, prueba y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.Series(boston.target, name='PRICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: subir los archivos de datos a S3\n",
    "Cuando se construye un trabajo de capacitación utilizando SageMaker, se ejecuta un contenedor que realiza la operación de capacitación. Este contenedor tiene acceso a los datos almacenados en S3. Esto significa que necesitamos cargar los datos que queremos usar para el entrenamiento en S3. Además, cuando realizamos un trabajo de transformación por lotes, SageMaker espera que los datos de entrada se almacenen en S3. Podemos usar la API de SageMaker para hacer esto y ocultar algunos de los detalles.\n",
    "\n",
    "### Guardar los datos localmente\n",
    "Primero necesitamos crear los archivos csv de prueba, capacitación y validación que luego cargaremos en S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Data/boston'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subir a S3\n",
    "Dado que actualmente estamos ejecutando dentro de una sesión de SageMaker, podemos usar el objeto que representa esta sesión para cargar nuestros datos en el depósito S3 'predeterminado'. Tenga en cuenta que es una buena práctica proporcionar un prefijo personalizado (esencialmente una carpeta S3) para asegurarse de que no interfiere accidentalmente con los datos cargados desde algún otro cuaderno o proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'boston-xgboost-hl'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: entrena el modelo XGBoost\n",
    "Ahora que tenemos los datos de entrenamiento y validación cargados en S3, podemos construir nuestro modelo XGBoost y entrenarlo. Haremos uso de la API de SageMaker de alto nivel para hacer esto, lo que hará que el código resultante sea un poco más fácil de leer a costa de cierta flexibilidad.\n",
    "\n",
    "Para construir un estimador, el objeto que deseamos entrenar, necesitamos proporcionar la ubicación de un contenedor que contenga el código de entrenamiento. Como estamos utilizando un algoritmo incorporado, Amazon proporciona este contenedor. Sin embargo, el nombre completo del contenedor es un poco largo y depende de la región en la que estamos operando. Afortunadamente, SageMaker proporciona un método útil llamado **get_image_uri** que construye el nombre de la imagen para nosotros.\n",
    "\n",
    "Para usar el método **get_image_uri**, debemos proporcionarle nuestra región actual, que se puede obtener del objeto de sesión, y el nombre del algoritmo que deseamos usar. En este cuaderno usaremos XGBoost, sin embargo, puede probar otro algoritmo si lo desea. La lista de algoritmos integrados se puede encontrar en la lista de Parámetros comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(session.boto_region_name, 'xgboost')\n",
    "\n",
    "# Construcción del objeto estimator\n",
    "xgb = sagemaker.estimator.Estimator(container, # El nombre de la imagen del contenedor de entrenamiento\n",
    "                                    role, # Rol que usamos (IAM)\n",
    "                                    train_instance_count=1, # Número de instancias para el entrenamiento\n",
    "                                    train_instance_type='ml.m4.xlarge', # Tipo de instancias para el entremaniento\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix), # Lugar donde se guarda la salida\n",
    "                                    sagemaker_session=session) # Sesión de SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de pedirle a SageMaker que comience el trabajo de capacitación, probablemente deberíamos configurar cualquier hiperparámetro específico del modelo. Hay bastantes que se pueden configurar al usar el algoritmo XGBoost, a continuación se detallan algunos de ellos. Si desea cambiar los hiperparámetros a continuación o modificar otros adicionales, puede encontrar información adicional en la página del hiperparámetro XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos nuestro objeto estimador completamente configurado, es hora de crear el sintonizador de hiperparámetro. Para hacer esto, necesitamos construir un nuevo objeto que contenga cada uno de los parámetros que queremos que SageMaker ajuste. En este caso, deseamos encontrar los mejores valores para los parámetros max_depth, eta, min_child_weight, subsample y gamma. Tenga en cuenta que para cada parámetro que queremos que SageMaker ajuste, necesitamos especificar tanto el tipo del parámetro como el rango de valores que ese parámetro puede tomar.\n",
    "\n",
    "Además, especificamos el número de modelos a construir (max_jobs) y el número de aquellos que pueden entrenarse en paralelo (max_parallel_jobs). En la celda a continuación hemos elegido entrenar 20 modelos, de los cuales pedimos que SageMaker entrene 3 a la vez en paralelo. Tenga en cuenta que esto da como resultado un total de 20 trabajos de capacitación que se ejecutan, lo que puede llevar algún tiempo, en este caso, casi media hora. Con modelos más complicados, esto puede llevar aún más tiempo, ¡así que ten en cuenta!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator=xgb,\n",
    "                                               objective_metric_name='validation:rmse',\n",
    "                                               objective_type='Minimize',\n",
    "                                               max_jobs=20,\n",
    "                                               max_parallel_jobs=3,\n",
    "                                               hyperparameter_ranges={\n",
    "                                                   'max_depth': IntegerParameter(3, 12),\n",
    "                                                   'eta': ContinuosParameter(0.05, 0.5),\n",
    "                                                   'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                   'subsample': ContinuosParameter(0.5, 0.9),\n",
    "                                                   'gamma': ContinousParameter(0, 10)\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos nuestro objeto sintonizador de hiperparámetros completamente configurado, es hora de entrenarlo. Para hacer esto, nos aseguramos de que SageMaker sepa que nuestros datos de entrada están en formato csv y luego ejecutamos el método de ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en muchos de los ejemplos que hemos visto hasta ahora, el método **fit()** se encarga de configurar y ajustar una serie de modelos diferentes, cada uno con hiperparámetros diferentes. Si deseamos esperar a que termine este proceso, podemos llamar al método **wait()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que el sintonizador de hiperamater ha terminado, podemos recuperar información sobre el modelo con mejor rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, dado que nos gustaría configurar un trabajo de transformación por lotes para probar el mejor modelo, podemos construir un nuevo objeto estimador a partir de los resultados del mejor trabajo de capacitación. El objeto xgb_attached a continuación ahora se puede usar como si construyéramos un estimador con los hiperparámetros de mejor rendimiento y luego lo ajustamos a nuestros datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: prueba el modelo\n",
    "Ahora que tenemos nuestro modelo de mejor rendimiento, podemos probarlo. Para hacer esto, utilizaremos la funcionalidad de transformación por lotes. Para empezar, necesitamos construir un objeto transformador a partir de nuestro modelo de ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer = xgb_attached.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, le pedimos a SageMaker que comience un trabajo de transformación por lotes utilizando nuestro modelo entrenado y aplicándolo a los datos de prueba que almacenamos previamente en S3. Tenemos que asegurarnos de proporcionar a SageMaker el tipo de datos que estamos proporcionando a nuestro modelo, en nuestro caso text/csv, para que sepa cómo serializar nuestros datos. Además, debemos asegurarnos de que SageMaker sepa cómo dividir nuestros datos en fragmentos si todo el conjunto de datos es demasiado grande para enviarlo a nuestro modelo de una vez.\n",
    "\n",
    "Tenga en cuenta que cuando le pedimos a SageMaker que haga esto, ejecutará el trabajo de transformación por lotes en segundo plano. Como debemos esperar los resultados de este trabajo antes de poder continuar, utilizamos el método **wait()**. Un beneficio adicional de esto es que obtenemos algunos resultados de nuestro trabajo de transformación por lotes que nos permite saber si algo salió mal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que el trabajo de transformación por lotes ha finalizado, la salida resultante se almacena en S3. Como deseamos analizar la salida dentro de nuestra computadora portátil, podemos usar un poco de magia de la computadora portátil para copiar el archivo de salida desde su ubicación S3 y guardarlo localmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver qué tan bien funciona nuestro modelo, podemos crear un diagrama de dispersión simple entre los valores predichos y los reales. Si el modelo fuera completamente exacto, el diagrama de dispersión resultante se vería como la línea $x = y$. Como podemos ver, nuestro modelo parece haber funcionado bien, pero hay margen de mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Median Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Median Price vs Predicted Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opcional: limpiar\n",
    "La instancia de notebook predeterminada en SageMaker no tiene mucho espacio en disco disponible. A medida que continúe completando y ejecutando cuadernos, eventualmente llenará este espacio en disco, lo que generará errores que pueden ser difíciles de diagnosticar. Una vez que haya terminado de usar un cuaderno, es una buena idea eliminar los archivos que creó en el camino. Por supuesto, puede hacerlo desde la terminal o desde el hub del portátil si lo desea. La celda a continuación contiene algunos comandos para limpiar los archivos creados desde el cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm $data_dir/*\n",
    "\n",
    "!rmdir $data_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
